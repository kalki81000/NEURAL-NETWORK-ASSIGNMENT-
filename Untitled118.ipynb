{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOAKMicwLwabSUOzwDFiVQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalki81000/NEURAL-NETWORK-ASSIGNMENT-/blob/main/Untitled118.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Deep Learning Frameworks\n",
        "\n"
      ],
      "metadata": {
        "id": "b_iEMLxMAhyZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bGUAAhgAGgy"
      },
      "outputs": [],
      "source": [
        "1.#  What is TensorFlow 2.0, and how is it different from TensorFlow 1.x ?\n",
        "**TensorFlow 2.0** is a major upgrade of Google’s open-source deep learning framework, released in September 2019, designed to make model building easier, more intuitive, and more flexible than **TensorFlow 1.x**.\n",
        "It focuses on simplicity, ease of use, and integration with modern Python programming practices.\n",
        "## **Key Differences between TensorFlow 2.0 and TensorFlow 1.x**\n",
        "\n",
        "| Feature / Aspect         | TensorFlow 1.x                                                                                                           | TensorFlow 2.0                                                                                                                              |\n",
        "| ------------------------ | ------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **Execution Mode**       | *Default*: **Graph Execution** (define-and-run) — you first define a static computation graph, then run it in a session. | *Default*: **Eager Execution** (define-by-run) — operations execute immediately as you write them, making debugging and prototyping easier. |\n",
        "| **Ease of Use**          | More verbose; requires sessions, placeholders, and manual graph management.                                              | Simplified, Pythonic API — no need for `tf.Session()` or `tf.placeholder()`.                                                                |\n",
        "| **Keras Integration**    | Keras was separate; TF had its own lower-level API.                                                                      | **`tf.keras`** is the default high-level API for building and training models.                                                              |\n",
        "| **API Simplification**   | Many redundant APIs; confusing for beginners.                                                                            | Cleaned-up API — deprecated unused functions, consolidated many methods.                                                                    |\n",
        "| **Control Flow**         | Uses `tf.while_loop`, `tf.cond` — graph-based and less intuitive.                                                        | Native Python control flow works directly with eager execution.                                                                             |\n",
        "| **Model Building**       | Sequential / functional APIs not tightly integrated; Estimators heavily used.                                            | Encourages **Keras Sequential, Functional, and subclassing APIs** for model creation.                                                       |\n",
        "| **Distributed Training** | Complex setup using `tf.distribute` in 1.x.                                                                              | Unified, simpler distributed training API (`tf.distribute.Strategy`).                                                                       |\n",
        "| **Compatibility**        | Older syntax; upgrading requires significant code changes.                                                               | Has a **`tf.compat.v1`** module to help run old 1.x code.                                                                                   |\n",
        "| **Default Behavior**     | Static computation graph by default.                                                                                     | Dynamic execution by default.                                                                                                               |\n",
        "\n",
        "### **Example: Code Comparison**\n",
        "\n",
        "**TensorFlow 1.x**\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.placeholder(tf.float32)\n",
        "y = tf.placeholder(tf.float32)\n",
        "z = x + y\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    result = sess.run(z, feed_dict={x: 3, y: 4})\n",
        "    print(result)\n",
        "```\n",
        "\n",
        "**TensorFlow 2.0**\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.constant(3.0)\n",
        "y = tf.constant(4.0)\n",
        "z = x + y\n",
        "\n",
        "print(z.numpy())\n",
        "```\n",
        "\n",
        "No sessions, no placeholders — just Python code that runs immediately."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2.How do you install TensorFlow 2.02\n",
        "Installing **TensorFlow 2.0** is straightforward — it’s done through `pip` (Python’s package manager).\n",
        "## **1. Basic Installation (CPU Version)**\n",
        "\n",
        "If you just want TensorFlow 2 (CPU-only, lighter installation):\n",
        "\n",
        "```bash\n",
        "pip install tensorflow==2.0.0\n",
        "```\n",
        "## **2. GPU Version (with CUDA support)**\n",
        "\n",
        "If your system has a compatible NVIDIA GPU and you’ve installed the required CUDA and cuDNN versions:\n",
        "\n",
        "```bash\n",
        "pip install tensorflow-gpu==2.0.0\n",
        "```\n",
        "\n",
        "> In TensorFlow versions after 2.1, `tensorflow` automatically includes GPU support if CUDA is present — no separate `tensorflow-gpu` package is needed. But for **exactly 2.0**, you must use `tensorflow-gpu` for GPU.\n",
        "\n",
        "## **3. Verify Installation**\n",
        "\n",
        "After installation, check the version:\n",
        "\n",
        "```bash\n",
        "python -c \"import tensorflow as tf; print(tf.__version__)\"\n",
        "```\n",
        "\n",
        "It should output:\n",
        "\n",
        "```\n",
        "2.0.0\n",
        "```\n",
        "## **4. Recommended: Virtual Environment**\n",
        "\n",
        "To avoid conflicts with other Python packages:\n",
        "\n",
        "```bash\n",
        "# Create a new environment\n",
        "python -m venv tf_env\n",
        "\n",
        "# Activate the environment\n",
        "# On Windows:\n",
        "tf_env\\Scripts\\activate\n",
        "# On Mac/Linux:\n",
        "source tf_env/bin/activate\n",
        "\n",
        "# Install TensorFlow 2.0\n",
        "pip install tensorflow==2.0.0\n",
        "```"
      ],
      "metadata": {
        "id": "tDSd4Gh7BtLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. What is the primary function of the tf.function in TensorFlow 2.02\n",
        "In **TensorFlow 2.0.2**, the **primary function** of `tf.function` is to **convert a regular Python function into a TensorFlow computation graph** for **faster execution and optimizations**.\n",
        "### **Why it matters**\n",
        "\n",
        "* TensorFlow 2 runs in **eager execution mode** by default (operations run immediately).\n",
        "* While eager execution is great for debugging, it’s slower than graph execution.\n",
        "* `tf.function` lets you keep the easy-to-read Python style **but** execute as an optimized graph under the hood.\n",
        "### **How it works**\n",
        "\n",
        "When you decorate a function with `@tf.function`:\n",
        "\n",
        "1. TensorFlow **traces** the Python code the first time it’s called.\n",
        "2. It **builds a computation graph** from that code.\n",
        "3. On subsequent calls, it runs the **compiled graph** directly instead of reinterpreting Python code each time.\n",
        "### **Example**\n",
        "\n",
        "**Without `tf.function` (Eager Execution)**\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "def add(a, b):\n",
        "    return a + b\n",
        "\n",
        "print(add(tf.constant(3), tf.constant(4)))  # Runs eagerly\n",
        "```\n",
        "\n",
        "**With `tf.function` (Graph Execution)**\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "@tf.function\n",
        "def add(a, b):\n",
        "    return a + b\n",
        "\n",
        "print(add(tf.constant(3), tf.constant(4)))  # Runs as a compiled graph\n",
        "```\n",
        "### **Key Benefits**\n",
        "\n",
        "* **Performance**: Graph execution can be much faster for repeated operations.\n",
        "* **Optimizations**: TensorFlow can apply advanced optimizations like operation fusion.\n",
        "* **Deployment**: Graphs can be saved and run on different devices/environments.\n",
        "💡 **In short:**\n",
        "`tf.function` is TensorFlow 2.0.2’s **bridge between eager execution and graph mode**, letting you write code naturally while still getting the **speed of static graphs**"
      ],
      "metadata": {
        "id": "CmlFB5sBEoCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4 What is the purpose of the Model class in TensorFlow 2.40\n",
        "In **TensorFlow 2.0.2**, the **`Model` class** (from `tf.keras.Model`) is the **core class for building, training, evaluating, and saving neural networks**.\n",
        "\n",
        "It’s the backbone of the **Keras API** inside TensorFlow, and all models — whether `Sequential`, functional, or subclassed — are instances of this class (directly or indirectly).\n",
        "## **Purpose of the `Model` class**\n",
        "\n",
        "1. **Encapsulate a neural network’s architecture**\n",
        "\n",
        "   * Stores the network’s layers, inputs, and outputs.\n",
        "   * Handles forward propagation (`call` method).\n",
        "\n",
        "2. **Provide training and evaluation utilities**\n",
        "\n",
        "   * `model.compile(...)` — set loss, optimizer, and metrics.\n",
        "   * `model.fit(...)` — train the model.\n",
        "   * `model.evaluate(...)` — test the model.\n",
        "   * `model.predict(...)` — run inference.\n",
        "\n",
        "3. **Manage model state**\n",
        "\n",
        "   * Tracks weights and parameters.\n",
        "   * Saves/loads the model (`model.save`, `tf.keras.models.load_model`).\n",
        "\n",
        "4. **Support subclassing for custom behavior**\n",
        "\n",
        "   * You can create your own model by subclassing `tf.keras.Model` and writing a custom `call()` method.\n",
        "## **Example: Using `Model` via the Functional API**\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "# Define layers\n",
        "inputs = tf.keras.Input(shape=(28, 28))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create Model\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile and train\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model.fit(x_train, y_train, epochs=5)  # Example training call\n",
        "```\n",
        "## **Example: Subclassing the `Model` class**\n",
        "\n",
        "```python\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.flatten = layers.Flatten()\n",
        "        self.dense1 = layers.Dense(128, activation='relu')\n",
        "        self.dense2 = layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.flatten(inputs)\n",
        "        x = self.dense1(x)\n",
        "        return self.dense2(x)\n",
        "\n",
        "model = MyModel()\n",
        "```\n",
        "✅ **In short:**\n",
        "The `Model` class in TensorFlow 2.0.2 is the **central object that represents your neural network** — it stores layers, runs forward passes, manages training, and handles saving/loading."
      ],
      "metadata": {
        "id": "Q6znOC0rGWv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5 How do you create a neural network using TensorFlow 2.0 ?\n",
        "In **TensorFlow 2.0.2**, you can create a neural network in **three main ways**:\n",
        "\n",
        "1. **Sequential API** — Best for simple, layer-by-layer models.\n",
        "2. **Functional API** — For complex architectures like multi-input/output or skip connections.\n",
        "3. **Subclassing `tf.keras.Model`** — For full customization.\n",
        "## **1️⃣ Sequential API (Simple, Linear Stack)**\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(784,)),  # Input layer\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')  # Output layer\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train (example with dummy data)\n",
        "import numpy as np\n",
        "x_train = np.random.random((1000, 784))\n",
        "y_train = np.random.randint(10, size=(1000,))\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32)\n",
        "```\n",
        "## **2️⃣ Functional API (More Flexible)**\n",
        "\n",
        "```python\n",
        "from tensorflow.keras import Input, Model\n",
        "\n",
        "# Input layer\n",
        "inputs = Input(shape=(784,))\n",
        "x = layers.Dense(128, activation='relu')(inputs)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create model\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "```\n",
        "## **3️⃣ Subclassing `tf.keras.Model` (Custom Behavior)**\n",
        "\n",
        "```python\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.d1 = layers.Dense(128, activation='relu')\n",
        "        self.d2 = layers.Dense(64, activation='relu')\n",
        "        self.d3 = layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.d1(x)\n",
        "        x = self.d2(x)\n",
        "        return self.d3(x)\n",
        "\n",
        "# Create and compile\n",
        "model = MyModel()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "```\n",
        "### **Steps for all approaches**\n",
        "\n",
        "1. **Define the model** (Sequential, Functional, or Subclassing).\n",
        "2. **Compile** — choose optimizer, loss, and metrics.\n",
        "3. **Fit** — train with `model.fit()`.\n",
        "4. **Evaluate** — test with `model.evaluate()`.\n",
        "5. **Predict** — use `model.predict()` for inference.\n"
      ],
      "metadata": {
        "id": "ZEba8eSgHsWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6 What is the importance of Tensor Space in TensorFlow2\n",
        "In **TensorFlow 2**, the concept of a **Tensor space** is important because it defines the “mathematical universe” in which all data and computations in TensorFlow happen.\n",
        "\n",
        "Think of it as the **coordinate system + dimensions + rules** that govern how TensorFlow stores, manipulates, and transforms data.\n",
        "\n",
        "---\n",
        "\n",
        "## **1. What is a Tensor Space?**\n",
        "\n",
        "A **tensor** in TensorFlow is a **multi-dimensional array** (like a generalization of scalars, vectors, and matrices).\n",
        "The **tensor space** refers to:\n",
        "\n",
        "* All possible tensors of a given **shape** (dimensions)\n",
        "* With a specific **data type** (dtype)\n",
        "* Living on a specific **device** (CPU, GPU, TPU)\n",
        "\n",
        "Example:\n",
        "\n",
        "* **Scalar space** → shape `()` (0D tensor)\n",
        "* **Vector space** → shape `(n,)` (1D tensor)\n",
        "* **Matrix space** → shape `(m, n)` (2D tensor)\n",
        "* **Higher-order tensor space** → shape `(d1, d2, ..., dn)`\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Why It’s Important in TensorFlow 2**\n",
        "\n",
        "1. **Foundation of Computation**\n",
        "\n",
        "   * All inputs, outputs, and parameters in a TensorFlow model live in a tensor space.\n",
        "   * Even model weights are tensors inside a defined space.\n",
        "\n",
        "2. **Shape Consistency**\n",
        "\n",
        "   * TensorFlow enforces shape compatibility during operations.\n",
        "   * Example: Adding two tensors requires them to be in the same **space** (shape + dtype).\n",
        "\n",
        "3. **Performance Optimization**\n",
        "\n",
        "   * The tensor space determines how data is laid out in memory, which affects speed.\n",
        "   * TensorFlow can optimize operations when tensor spaces are known.\n",
        "\n",
        "4. **Device Placement**\n",
        "\n",
        "   * The tensor space also includes the **device** location (e.g., `CPU:0`, `GPU:0`).\n",
        "   * This helps TensorFlow schedule operations efficiently.\n",
        "\n",
        "5. **Mathematical Abstraction**\n",
        "\n",
        "   * Neural networks are built on linear algebra, and tensor spaces are the “vector spaces” in which these transformations happen.\n",
        "\n",
        "---\n",
        "\n",
        "## **3. Example**\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create tensors in a specific space\n",
        "t1 = tf.constant([1, 2, 3], dtype=tf.float32)  # 1D space, float32\n",
        "t2 = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)  # 2D space\n",
        "\n",
        "# Operations happen within compatible tensor spaces\n",
        "result = tf.matmul(t2, tf.reshape(t1[:2], (2, 1)))  # Matmul in 2D space\n",
        "print(result)\n",
        "```\n",
        "\n",
        "Here:\n",
        "\n",
        "* `t1` lives in a **vector space** (shape `(3,)`, dtype `float32`)\n",
        "* `t2` lives in a **matrix space** (shape `(2,2)`, dtype `float32`)\n",
        "* We reshape `t1` to match the **space** needed for matrix multiplication.\n",
        "\n",
        "---\n",
        "\n",
        "✅ **In short:**\n",
        "In TensorFlow 2, **tensor space** is important because it defines the **structure, type, and device context** of all data. Correctly managing tensor spaces ensures mathematical correctness, efficient computation, and compatibility between operations."
      ],
      "metadata": {
        "id": "9PWXGb-TIMNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7 How can TensorBoard be integrated with TensorFlow 2.02\n",
        "In **TensorFlow 2.0.2**, **TensorBoard** is directly integrated into the training workflow through `tf.keras.callbacks.TensorBoard`.\n",
        "It allows you to **visualize training progress, metrics, model graphs, and more** in your browser.\n",
        "## **1️⃣ Install TensorBoard**\n",
        "\n",
        "If it’s not already installed:\n",
        "\n",
        "```bash\n",
        "pip install tensorboard\n",
        "```\n",
        "## **2️⃣ Basic Integration with `model.fit()`**\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "# Dummy data\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Simple model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Create log directory with timestamp\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Train with TensorBoard callback\n",
        "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test),\n",
        "          callbacks=[tensorboard_callback])\n",
        "```\n",
        "## **3️⃣ Launch TensorBoard**\n",
        "\n",
        "In a terminal:\n",
        "\n",
        "```bash\n",
        "tensorboard --logdir=logs/fit\n",
        "```\n",
        "\n",
        "Then open in your browser:\n",
        "\n",
        "```\n",
        "http://localhost:6006\n",
        "```\n",
        "\n",
        "## **4️⃣ What You Can See in TensorBoard**\n",
        "\n",
        "* **Scalars** → Loss, accuracy, learning rate over epochs.\n",
        "* **Graphs** → Model computation graph.\n",
        "* **Histograms** → Weight and bias distributions.\n",
        "* **Images** → Sample data or filters.\n",
        "* **Projector** → Embedding visualizations.\n",
        "## **5️⃣ Example for Custom Training Loops**\n",
        "\n",
        "If you use `tf.GradientTape` instead of `model.fit()`, you can still log to TensorBoard:\n",
        "\n",
        "```python\n",
        "writer = tf.summary.create_file_writer(log_dir)\n",
        "\n",
        "with writer.as_default():\n",
        "    for step in range(100):\n",
        "        tf.summary.scalar('my_metric', step ** 0.5, step=step)\n",
        "``\n",
        "✅ **In short:**\n",
        "You integrate TensorBoard in TensorFlow 2.0.2 by creating a `TensorBoard` callback and passing it to `model.fit()`, then launch TensorBoard to visualize the logs.\n",
        "\n",
        "If you want, I can give you a **TensorFlow 2.0.2 + TensorBoard training workflow diagram** so the whole process from training to visualization is crystal clear. Would you like me to prepare that?\n"
      ],
      "metadata": {
        "id": "DkxaHHbWI7a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8 What is the purpose of TensorFlow Playground2\n",
        "**TensorFlow Playground** isn’t actually part of the TensorFlow 2.0.2 library — it’s an **interactive, browser-based tool** made by the TensorFlow team that lets you **experiment with and visualize how neural networks learn**.\n",
        "\n",
        "It’s available here: [https://playground.tensorflow.org](https://playground.tensorflow.org)\n",
        "## **Purpose of TensorFlow Playground**\n",
        "\n",
        "1. **Educational Demonstration**\n",
        "\n",
        "   * Helps beginners understand core neural network concepts without coding.\n",
        "   * Lets you *see* how network layers, neurons, activation functions, and learning rates affect results.\n",
        "\n",
        "2. **Visual Intuition**\n",
        "\n",
        "   * Shows data points and decision boundaries in real time as the model trains.\n",
        "   * Displays weight connections with varying strengths (thicker/darker lines = stronger weights).\n",
        "\n",
        "3. **Experimentation Without Setup**\n",
        "\n",
        "   * No Python, no installations — it runs entirely in the browser using JavaScript.\n",
        "   * Instant feedback on changes to architecture or hyperparameters.\n",
        "\n",
        "4. **Concept Testing**\n",
        "\n",
        "   * You can quickly try:\n",
        "\n",
        "     * Number of hidden layers/neurons\n",
        "     * Activation functions\n",
        "     * Learning rate changes\n",
        "     * Regularization strength\n",
        "     * Input feature selection\n",
        "## **Example Features**\n",
        "\n",
        "* **Datasets**: Spiral, circles, clusters, etc.\n",
        "* **Architecture Control**: Add/remove layers and neurons.\n",
        "* **Training Settings**: Batch size, learning rate, activation functions.\n",
        "* **Regularization**: L1/L2 penalties to prevent overfitting.\n",
        "* **Real-time Visualization**: Decision boundaries and loss curves update as training progresses.\n",
        "✅ **In short:**\n",
        "The purpose of **TensorFlow Playground** is to **teach and demonstrate how neural networks work** by letting you experiment visually and interactively — making abstract ML concepts more concrete."
      ],
      "metadata": {
        "id": "7ne3_CZRJfYP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}