{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhusg2OozJwH2KOi9uHTB/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalki81000/NEURAL-NETWORK-ASSIGNMENT-/blob/main/Untitled118.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Deep Learning Frameworks\n",
        "\n"
      ],
      "metadata": {
        "id": "b_iEMLxMAhyZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bGUAAhgAGgy"
      },
      "outputs": [],
      "source": [
        "1.#  What is TensorFlow 2.0, and how is it different from TensorFlow 1.x ?\n",
        "**TensorFlow 2.0** is a major upgrade of Google’s open-source deep learning framework, released in September 2019, designed to make model building easier, more intuitive, and more flexible than **TensorFlow 1.x**.\n",
        "It focuses on simplicity, ease of use, and integration with modern Python programming practices.\n",
        "## **Key Differences between TensorFlow 2.0 and TensorFlow 1.x**\n",
        "\n",
        "| Feature / Aspect         | TensorFlow 1.x                                                                                                           | TensorFlow 2.0                                                                                                                              |\n",
        "| ------------------------ | ------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **Execution Mode**       | *Default*: **Graph Execution** (define-and-run) — you first define a static computation graph, then run it in a session. | *Default*: **Eager Execution** (define-by-run) — operations execute immediately as you write them, making debugging and prototyping easier. |\n",
        "| **Ease of Use**          | More verbose; requires sessions, placeholders, and manual graph management.                                              | Simplified, Pythonic API — no need for `tf.Session()` or `tf.placeholder()`.                                                                |\n",
        "| **Keras Integration**    | Keras was separate; TF had its own lower-level API.                                                                      | **`tf.keras`** is the default high-level API for building and training models.                                                              |\n",
        "| **API Simplification**   | Many redundant APIs; confusing for beginners.                                                                            | Cleaned-up API — deprecated unused functions, consolidated many methods.                                                                    |\n",
        "| **Control Flow**         | Uses `tf.while_loop`, `tf.cond` — graph-based and less intuitive.                                                        | Native Python control flow works directly with eager execution.                                                                             |\n",
        "| **Model Building**       | Sequential / functional APIs not tightly integrated; Estimators heavily used.                                            | Encourages **Keras Sequential, Functional, and subclassing APIs** for model creation.                                                       |\n",
        "| **Distributed Training** | Complex setup using `tf.distribute` in 1.x.                                                                              | Unified, simpler distributed training API (`tf.distribute.Strategy`).                                                                       |\n",
        "| **Compatibility**        | Older syntax; upgrading requires significant code changes.                                                               | Has a **`tf.compat.v1`** module to help run old 1.x code.                                                                                   |\n",
        "| **Default Behavior**     | Static computation graph by default.                                                                                     | Dynamic execution by default.                                                                                                               |\n",
        "\n",
        "### **Example: Code Comparison**\n",
        "\n",
        "**TensorFlow 1.x**\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.placeholder(tf.float32)\n",
        "y = tf.placeholder(tf.float32)\n",
        "z = x + y\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    result = sess.run(z, feed_dict={x: 3, y: 4})\n",
        "    print(result)\n",
        "```\n",
        "\n",
        "**TensorFlow 2.0**\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.constant(3.0)\n",
        "y = tf.constant(4.0)\n",
        "z = x + y\n",
        "\n",
        "print(z.numpy())\n",
        "```\n",
        "\n",
        "No sessions, no placeholders — just Python code that runs immediately."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2.How do you install TensorFlow 2.02\n",
        "Installing **TensorFlow 2.0** is straightforward — it’s done through `pip` (Python’s package manager).\n",
        "## **1. Basic Installation (CPU Version)**\n",
        "\n",
        "If you just want TensorFlow 2 (CPU-only, lighter installation):\n",
        "\n",
        "```bash\n",
        "pip install tensorflow==2.0.0\n",
        "```\n",
        "## **2. GPU Version (with CUDA support)**\n",
        "\n",
        "If your system has a compatible NVIDIA GPU and you’ve installed the required CUDA and cuDNN versions:\n",
        "\n",
        "```bash\n",
        "pip install tensorflow-gpu==2.0.0\n",
        "```\n",
        "\n",
        "> In TensorFlow versions after 2.1, `tensorflow` automatically includes GPU support if CUDA is present — no separate `tensorflow-gpu` package is needed. But for **exactly 2.0**, you must use `tensorflow-gpu` for GPU.\n",
        "\n",
        "## **3. Verify Installation**\n",
        "\n",
        "After installation, check the version:\n",
        "\n",
        "```bash\n",
        "python -c \"import tensorflow as tf; print(tf.__version__)\"\n",
        "```\n",
        "\n",
        "It should output:\n",
        "\n",
        "```\n",
        "2.0.0\n",
        "```\n",
        "## **4. Recommended: Virtual Environment**\n",
        "\n",
        "To avoid conflicts with other Python packages:\n",
        "\n",
        "```bash\n",
        "# Create a new environment\n",
        "python -m venv tf_env\n",
        "\n",
        "# Activate the environment\n",
        "# On Windows:\n",
        "tf_env\\Scripts\\activate\n",
        "# On Mac/Linux:\n",
        "source tf_env/bin/activate\n",
        "\n",
        "# Install TensorFlow 2.0\n",
        "pip install tensorflow==2.0.0\n",
        "```"
      ],
      "metadata": {
        "id": "tDSd4Gh7BtLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. What is the primary function of the tf.function in TensorFlow 2.02\n",
        "In **TensorFlow 2.0.2**, the **primary function** of `tf.function` is to **convert a regular Python function into a TensorFlow computation graph** for **faster execution and optimizations**.\n",
        "### **Why it matters**\n",
        "\n",
        "* TensorFlow 2 runs in **eager execution mode** by default (operations run immediately).\n",
        "* While eager execution is great for debugging, it’s slower than graph execution.\n",
        "* `tf.function` lets you keep the easy-to-read Python style **but** execute as an optimized graph under the hood.\n",
        "### **How it works**\n",
        "\n",
        "When you decorate a function with `@tf.function`:\n",
        "\n",
        "1. TensorFlow **traces** the Python code the first time it’s called.\n",
        "2. It **builds a computation graph** from that code.\n",
        "3. On subsequent calls, it runs the **compiled graph** directly instead of reinterpreting Python code each time.\n",
        "### **Example**\n",
        "\n",
        "**Without `tf.function` (Eager Execution)**\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "def add(a, b):\n",
        "    return a + b\n",
        "\n",
        "print(add(tf.constant(3), tf.constant(4)))  # Runs eagerly\n",
        "```\n",
        "\n",
        "**With `tf.function` (Graph Execution)**\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "@tf.function\n",
        "def add(a, b):\n",
        "    return a + b\n",
        "\n",
        "print(add(tf.constant(3), tf.constant(4)))  # Runs as a compiled graph\n",
        "```\n",
        "### **Key Benefits**\n",
        "\n",
        "* **Performance**: Graph execution can be much faster for repeated operations.\n",
        "* **Optimizations**: TensorFlow can apply advanced optimizations like operation fusion.\n",
        "* **Deployment**: Graphs can be saved and run on different devices/environments.\n",
        "💡 **In short:**\n",
        "`tf.function` is TensorFlow 2.0.2’s **bridge between eager execution and graph mode**, letting you write code naturally while still getting the **speed of static graphs**"
      ],
      "metadata": {
        "id": "CmlFB5sBEoCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4 What is the purpose of the Model class in TensorFlow 2.40\n",
        "In **TensorFlow 2.0.2**, the **`Model` class** (from `tf.keras.Model`) is the **core class for building, training, evaluating, and saving neural networks**.\n",
        "\n",
        "It’s the backbone of the **Keras API** inside TensorFlow, and all models — whether `Sequential`, functional, or subclassed — are instances of this class (directly or indirectly).\n",
        "## **Purpose of the `Model` class**\n",
        "\n",
        "1. **Encapsulate a neural network’s architecture**\n",
        "\n",
        "   * Stores the network’s layers, inputs, and outputs.\n",
        "   * Handles forward propagation (`call` method).\n",
        "\n",
        "2. **Provide training and evaluation utilities**\n",
        "\n",
        "   * `model.compile(...)` — set loss, optimizer, and metrics.\n",
        "   * `model.fit(...)` — train the model.\n",
        "   * `model.evaluate(...)` — test the model.\n",
        "   * `model.predict(...)` — run inference.\n",
        "\n",
        "3. **Manage model state**\n",
        "\n",
        "   * Tracks weights and parameters.\n",
        "   * Saves/loads the model (`model.save`, `tf.keras.models.load_model`).\n",
        "\n",
        "4. **Support subclassing for custom behavior**\n",
        "\n",
        "   * You can create your own model by subclassing `tf.keras.Model` and writing a custom `call()` method.\n",
        "## **Example: Using `Model` via the Functional API**\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "# Define layers\n",
        "inputs = tf.keras.Input(shape=(28, 28))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create Model\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile and train\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model.fit(x_train, y_train, epochs=5)  # Example training call\n",
        "```\n",
        "## **Example: Subclassing the `Model` class**\n",
        "\n",
        "```python\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.flatten = layers.Flatten()\n",
        "        self.dense1 = layers.Dense(128, activation='relu')\n",
        "        self.dense2 = layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.flatten(inputs)\n",
        "        x = self.dense1(x)\n",
        "        return self.dense2(x)\n",
        "\n",
        "model = MyModel()\n",
        "```\n",
        "✅ **In short:**\n",
        "The `Model` class in TensorFlow 2.0.2 is the **central object that represents your neural network** — it stores layers, runs forward passes, manages training, and handles saving/loading."
      ],
      "metadata": {
        "id": "Q6znOC0rGWv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5 How do you create a neural network using TensorFlow 2.0 ?\n",
        "In **TensorFlow 2.0.2**, you can create a neural network in **three main ways**:\n",
        "\n",
        "1. **Sequential API** — Best for simple, layer-by-layer models.\n",
        "2. **Functional API** — For complex architectures like multi-input/output or skip connections.\n",
        "3. **Subclassing `tf.keras.Model`** — For full customization.\n",
        "## **1️⃣ Sequential API (Simple, Linear Stack)**\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(784,)),  # Input layer\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')  # Output layer\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train (example with dummy data)\n",
        "import numpy as np\n",
        "x_train = np.random.random((1000, 784))\n",
        "y_train = np.random.randint(10, size=(1000,))\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32)\n",
        "```\n",
        "## **2️⃣ Functional API (More Flexible)**\n",
        "\n",
        "```python\n",
        "from tensorflow.keras import Input, Model\n",
        "\n",
        "# Input layer\n",
        "inputs = Input(shape=(784,))\n",
        "x = layers.Dense(128, activation='relu')(inputs)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create model\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "```\n",
        "## **3️⃣ Subclassing `tf.keras.Model` (Custom Behavior)**\n",
        "\n",
        "```python\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.d1 = layers.Dense(128, activation='relu')\n",
        "        self.d2 = layers.Dense(64, activation='relu')\n",
        "        self.d3 = layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.d1(x)\n",
        "        x = self.d2(x)\n",
        "        return self.d3(x)\n",
        "\n",
        "# Create and compile\n",
        "model = MyModel()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "```\n",
        "### **Steps for all approaches**\n",
        "\n",
        "1. **Define the model** (Sequential, Functional, or Subclassing).\n",
        "2. **Compile** — choose optimizer, loss, and metrics.\n",
        "3. **Fit** — train with `model.fit()`.\n",
        "4. **Evaluate** — test with `model.evaluate()`.\n",
        "5. **Predict** — use `model.predict()` for inference.\n"
      ],
      "metadata": {
        "id": "ZEba8eSgHsWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6 What is the importance of Tensor Space in TensorFlow2\n",
        "In **TensorFlow 2**, the concept of a **Tensor space** is important because it defines the “mathematical universe” in which all data and computations in TensorFlow happen.\n",
        "\n",
        "Think of it as the **coordinate system + dimensions + rules** that govern how TensorFlow stores, manipulates, and transforms data.\n",
        "\n",
        "---\n",
        "\n",
        "## **1. What is a Tensor Space?**\n",
        "\n",
        "A **tensor** in TensorFlow is a **multi-dimensional array** (like a generalization of scalars, vectors, and matrices).\n",
        "The **tensor space** refers to:\n",
        "\n",
        "* All possible tensors of a given **shape** (dimensions)\n",
        "* With a specific **data type** (dtype)\n",
        "* Living on a specific **device** (CPU, GPU, TPU)\n",
        "\n",
        "Example:\n",
        "\n",
        "* **Scalar space** → shape `()` (0D tensor)\n",
        "* **Vector space** → shape `(n,)` (1D tensor)\n",
        "* **Matrix space** → shape `(m, n)` (2D tensor)\n",
        "* **Higher-order tensor space** → shape `(d1, d2, ..., dn)`\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Why It’s Important in TensorFlow 2**\n",
        "\n",
        "1. **Foundation of Computation**\n",
        "\n",
        "   * All inputs, outputs, and parameters in a TensorFlow model live in a tensor space.\n",
        "   * Even model weights are tensors inside a defined space.\n",
        "\n",
        "2. **Shape Consistency**\n",
        "\n",
        "   * TensorFlow enforces shape compatibility during operations.\n",
        "   * Example: Adding two tensors requires them to be in the same **space** (shape + dtype).\n",
        "\n",
        "3. **Performance Optimization**\n",
        "\n",
        "   * The tensor space determines how data is laid out in memory, which affects speed.\n",
        "   * TensorFlow can optimize operations when tensor spaces are known.\n",
        "\n",
        "4. **Device Placement**\n",
        "\n",
        "   * The tensor space also includes the **device** location (e.g., `CPU:0`, `GPU:0`).\n",
        "   * This helps TensorFlow schedule operations efficiently.\n",
        "\n",
        "5. **Mathematical Abstraction**\n",
        "\n",
        "   * Neural networks are built on linear algebra, and tensor spaces are the “vector spaces” in which these transformations happen.\n",
        "\n",
        "---\n",
        "\n",
        "## **3. Example**\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create tensors in a specific space\n",
        "t1 = tf.constant([1, 2, 3], dtype=tf.float32)  # 1D space, float32\n",
        "t2 = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)  # 2D space\n",
        "\n",
        "# Operations happen within compatible tensor spaces\n",
        "result = tf.matmul(t2, tf.reshape(t1[:2], (2, 1)))  # Matmul in 2D space\n",
        "print(result)\n",
        "```\n",
        "\n",
        "Here:\n",
        "\n",
        "* `t1` lives in a **vector space** (shape `(3,)`, dtype `float32`)\n",
        "* `t2` lives in a **matrix space** (shape `(2,2)`, dtype `float32`)\n",
        "* We reshape `t1` to match the **space** needed for matrix multiplication.\n",
        "\n",
        "---\n",
        "\n",
        "✅ **In short:**\n",
        "In TensorFlow 2, **tensor space** is important because it defines the **structure, type, and device context** of all data. Correctly managing tensor spaces ensures mathematical correctness, efficient computation, and compatibility between operations."
      ],
      "metadata": {
        "id": "9PWXGb-TIMNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7 How can TensorBoard be integrated with TensorFlow 2.02\n",
        "In **TensorFlow 2.0.2**, **TensorBoard** is directly integrated into the training workflow through `tf.keras.callbacks.TensorBoard`.\n",
        "It allows you to **visualize training progress, metrics, model graphs, and more** in your browser.\n",
        "## **1️⃣ Install TensorBoard**\n",
        "\n",
        "If it’s not already installed:\n",
        "\n",
        "```bash\n",
        "pip install tensorboard\n",
        "```\n",
        "## **2️⃣ Basic Integration with `model.fit()`**\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "# Dummy data\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Simple model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Create log directory with timestamp\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Train with TensorBoard callback\n",
        "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test),\n",
        "          callbacks=[tensorboard_callback])\n",
        "```\n",
        "## **3️⃣ Launch TensorBoard**\n",
        "\n",
        "In a terminal:\n",
        "\n",
        "```bash\n",
        "tensorboard --logdir=logs/fit\n",
        "```\n",
        "\n",
        "Then open in your browser:\n",
        "\n",
        "```\n",
        "http://localhost:6006\n",
        "```\n",
        "\n",
        "## **4️⃣ What You Can See in TensorBoard**\n",
        "\n",
        "* **Scalars** → Loss, accuracy, learning rate over epochs.\n",
        "* **Graphs** → Model computation graph.\n",
        "* **Histograms** → Weight and bias distributions.\n",
        "* **Images** → Sample data or filters.\n",
        "* **Projector** → Embedding visualizations.\n",
        "## **5️⃣ Example for Custom Training Loops**\n",
        "\n",
        "If you use `tf.GradientTape` instead of `model.fit()`, you can still log to TensorBoard:\n",
        "\n",
        "```python\n",
        "writer = tf.summary.create_file_writer(log_dir)\n",
        "\n",
        "with writer.as_default():\n",
        "    for step in range(100):\n",
        "        tf.summary.scalar('my_metric', step ** 0.5, step=step)\n",
        "``\n",
        "✅ **In short:**\n",
        "You integrate TensorBoard in TensorFlow 2.0.2 by creating a `TensorBoard` callback and passing it to `model.fit()`, then launch TensorBoard to visualize the logs.\n",
        "\n",
        "If you want, I can give you a **TensorFlow 2.0.2 + TensorBoard training workflow diagram** so the whole process from training to visualization is crystal clear. Would you like me to prepare that?\n"
      ],
      "metadata": {
        "id": "DkxaHHbWI7a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8 What is the purpose of TensorFlow Playground2\n",
        "**TensorFlow Playground** isn’t actually part of the TensorFlow 2.0.2 library — it’s an **interactive, browser-based tool** made by the TensorFlow team that lets you **experiment with and visualize how neural networks learn**.\n",
        "\n",
        "It’s available here: [https://playground.tensorflow.org](https://playground.tensorflow.org)\n",
        "## **Purpose of TensorFlow Playground**\n",
        "\n",
        "1. **Educational Demonstration**\n",
        "\n",
        "   * Helps beginners understand core neural network concepts without coding.\n",
        "   * Lets you *see* how network layers, neurons, activation functions, and learning rates affect results.\n",
        "\n",
        "2. **Visual Intuition**\n",
        "\n",
        "   * Shows data points and decision boundaries in real time as the model trains.\n",
        "   * Displays weight connections with varying strengths (thicker/darker lines = stronger weights).\n",
        "\n",
        "3. **Experimentation Without Setup**\n",
        "\n",
        "   * No Python, no installations — it runs entirely in the browser using JavaScript.\n",
        "   * Instant feedback on changes to architecture or hyperparameters.\n",
        "\n",
        "4. **Concept Testing**\n",
        "\n",
        "   * You can quickly try:\n",
        "\n",
        "     * Number of hidden layers/neurons\n",
        "     * Activation functions\n",
        "     * Learning rate changes\n",
        "     * Regularization strength\n",
        "     * Input feature selection\n",
        "## **Example Features**\n",
        "\n",
        "* **Datasets**: Spiral, circles, clusters, etc.\n",
        "* **Architecture Control**: Add/remove layers and neurons.\n",
        "* **Training Settings**: Batch size, learning rate, activation functions.\n",
        "* **Regularization**: L1/L2 penalties to prevent overfitting.\n",
        "* **Real-time Visualization**: Decision boundaries and loss curves update as training progresses.\n",
        "✅ **In short:**\n",
        "The purpose of **TensorFlow Playground** is to **teach and demonstrate how neural networks work** by letting you experiment visually and interactively — making abstract ML concepts more concrete."
      ],
      "metadata": {
        "id": "7ne3_CZRJfYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9 What is Netron, and how is it useful for deep learning models?\n",
        "Netron is an **open-source model visualizer** designed to help developers, researchers, and engineers **inspect and understand deep learning, machine learning, and neural network models**.\n",
        "\n",
        "### 🔹 What Netron Is\n",
        "* A **graphical viewer** that lets you **open, explore, and visualize the structure** of trained models.\n",
        "* Available as a **desktop app** (Windows, macOS, Linux), **web app**, and even as an **extension for VS Code**.\n",
        "### 🔹 Supported Model Formats\n",
        "Netron supports many popular frameworks and file formats, including:\n",
        "\n",
        "* **TensorFlow / Keras**: `.pb`, `.h5`, `.tflite`, `.json`, `.keras`\n",
        "* **PyTorch / TorchScript**: `.pt`, `.pth`, `.pkl`, `.onnx`\n",
        "* **ONNX**: `.onnx`\n",
        "* **Caffe / Caffe2**: `.caffemodel`, `.pbtxt`\n",
        "* **CoreML**: `.mlmodel`\n",
        "* **MXNet**: `.model`, `.params`, `.json`\n",
        "* Others (CNTK, Darknet, PaddlePaddle, scikit-learn, XGBoost, etc.)\n",
        "### 🔹 Why It’s Useful in Deep Learning\n",
        "\n",
        "1. **Model Structure Visualization**\n",
        "\n",
        "   * See the layers (Conv, Dense, LSTM, BatchNorm, etc.) in a **graph format**.\n",
        "   * Understand how inputs flow through the network to outputs.\n",
        "\n",
        "2. **Debugging & Verification**\n",
        "\n",
        "   * Quickly check if the model architecture matches expectations.\n",
        "   * Helps detect errors in model conversion (e.g., TensorFlow → ONNX).\n",
        "\n",
        "3. **Interoperability**\n",
        "\n",
        "   * Since it supports multiple frameworks, it’s helpful when sharing or deploying models across different platforms.\n",
        "\n",
        "4. **Transparency & Documentation**\n",
        "\n",
        "   * Makes models more understandable for teams, researchers, and even non-experts.\n",
        "   * Useful in presentations and reports.\n",
        "\n",
        "5. **No Training Needed**\n",
        "\n",
        "   * Netron only inspects the **static model file**, not the training process.\n",
        "   * It’s lightweight and doesn’t require GPU/CPU execution.\n"
      ],
      "metadata": {
        "id": "sxsszR7zIiV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10.What is the difference between TensorFlow and PyTorch?\n",
        "Great question! 🚀\n",
        "TensorFlow and PyTorch are the **two most widely used deep learning frameworks**, but they differ in philosophy, usability, and ecosystem.\n",
        "Here’s a structured comparison:\n",
        "## 🔹 1. **Origin & Popularity**\n",
        "\n",
        "* **TensorFlow (TF)**: Developed by Google Brain (2015). Widely used in industry, production, and large-scale deployments.\n",
        "* **PyTorch (PT)**: Developed by Facebook AI Research (2016). Became very popular in research for its flexibility and ease of use.\n",
        "## 🔹 2. **Programming Style**\n",
        "\n",
        "* **TensorFlow**:\n",
        "\n",
        "  * Initially **static computation graph** (define-and-run).\n",
        "  * TensorFlow 2.x introduced **Eager Execution** (define-by-run, like PyTorch).\n",
        "  * More boilerplate code compared to PyTorch (but improved with Keras API).\n",
        "* **PyTorch**:\n",
        "\n",
        "  * **Dynamic computation graph** (define-by-run).\n",
        "  * Feels more \"pythonic\" and intuitive for debugging.\n",
        "  * Easy to write and modify models on the fly.\n",
        "\n",
        "👉 **Key difference**: PyTorch is more *intuitive & flexible* for research; TensorFlow is more *structured* and geared toward production.\n",
        "## 🔹 3. **Model Deployment**\n",
        "\n",
        "* **TensorFlow**:\n",
        "\n",
        "  * TensorFlow Serving, TensorFlow Lite (mobile/IoT), TensorFlow\\.js (browser).\n",
        "  * Strong production ecosystem.\n",
        "* **PyTorch**:\n",
        "\n",
        "  * TorchServe, TorchScript, and PyTorch Mobile (improving fast).\n",
        "  * Deployment used to be weaker than TF, but catching up with ONNX support.\n",
        "## 🔹 4. **Ecosystem & Tools**\n",
        "\n",
        "* **TensorFlow**:\n",
        "\n",
        "  * Rich ecosystem: **TensorBoard** (visualization), **TF Hub** (pre-trained models), **TFX** (ML pipelines), **TPU support**.\n",
        "* **PyTorch**:\n",
        "\n",
        "  * Excellent for research: **TorchVision, TorchText, TorchAudio**.\n",
        "  * Hugely popular in academic papers.\n",
        "  * Visualization via TensorBoard (supported) or Visdom.\n",
        "## 🔹 5. **Community & Learning Curve**\n",
        "\n",
        "* **TensorFlow**:\n",
        "\n",
        "  * Larger industry adoption, many tutorials, but steeper learning curve (especially TF1.x).\n",
        "* **PyTorch**:\n",
        "\n",
        "  * Easier to learn and debug, strong research community.\n",
        "## 🔹 6. **Performance**\n",
        "\n",
        "* Both use **GPU acceleration (CUDA, cuDNN)** and support distributed training.\n",
        "* **TensorFlow** traditionally better optimized for production-scale workloads, but **PyTorch is catching up** with performance improvements.\n",
        "## ✅ Summary Table\n",
        "\n",
        "| Feature         | TensorFlow                          | PyTorch                              |\n",
        "| --------------- | ----------------------------------- | ------------------------------------ |\n",
        "| **Style**       | Static (TF1), Dynamic (TF2 + Keras) | Dynamic (define-by-run)              |\n",
        "| **Ease of Use** | More complex, better with Keras     | Very intuitive, Pythonic             |\n",
        "| **Deployment**  | Strong (TF Serving, Lite, JS, TPU)  | Improving (TorchServe, TorchScript)  |\n",
        "| **Ecosystem**   | Large (TFX, TensorBoard, TF Hub)    | Research-focused (TorchVision, etc.) |\n",
        "| **Community**   | Industry-heavy                      | Research-heavy                       |\n",
        "| **Performance** | Optimized for large-scale prod      | Excellent, catching up               |\n",
        "👉 **In simple terms**:\n",
        "\n",
        "* Use **PyTorch** if you’re doing research, experimenting, or want easy debugging.\n",
        "* Use **TensorFlow** if you need robust deployment, production pipelines, or TPU support."
      ],
      "metadata": {
        "id": "PQ---OgiJKtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. How do you install PyTorch ?\n",
        "Installing **PyTorch** depends on your operating system, Python version, and whether you want **CPU-only** or **GPU (CUDA)** support.\n",
        "\n",
        "Here’s a step-by-step guide:\n",
        "## 🔹 1. Using `pip` (most common)\n",
        "\n",
        "For **CPU-only**:\n",
        "\n",
        "```bash\n",
        "pip install torch torchvision torchaudio\n",
        "```\n",
        "\n",
        "For **GPU with CUDA** (example: CUDA 11.8):\n",
        "\n",
        "```bash\n",
        "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "```\n",
        "👉 Replace `cu118` with the CUDA version you want (`cu117`, `cu121`, etc.). If you’re not sure about CUDA, you can stick to **CPU-only** first.\n",
        "## 🔹 2. Using `conda`\n",
        "\n",
        "For **CPU-only**:\n",
        "\n",
        "```bash\n",
        "conda install pytorch torchvision torchaudio cpuonly -c pytorch\n",
        "``\n",
        "For **GPU with CUDA** (example: CUDA 11.8):\n",
        "\n",
        "```bash\n",
        "conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\n",
        "```\n",
        "## 🔹 3. Verify Installation\n",
        "\n",
        "Open Python and run:\n",
        "\n",
        "```python\n",
        "import torch\n",
        "print(torch.__version__)        # shows installed version\n",
        "print(torch.cuda.is_available())  # True if CUDA (GPU) is available.\n",
        "⚡ **Tip:**\n",
        "\n",
        "* If you don’t have an NVIDIA GPU or don’t need GPU acceleration → install the **CPU-only** version (lighter & simpler).\n",
        "* If you have an NVIDIA GPU → match your **CUDA version** with PyTorch’s supported builds.\n",
        "Do you want me to give you the **exact installation command** for your system (Windows/Linux, Python version, GPU/CPU)?\n"
      ],
      "metadata": {
        "id": "Q8Op9iziJ5Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#12 What is the basic structure of a PyTorch neural network ?\n",
        "In **PyTorch**, the basic structure of a neural network is built using the `torch.nn.Module` class.\n",
        "It provides a way to define layers and the forward pass.\n",
        "\n",
        "Here’s the general structure:\n",
        "### **1. Import required libraries**\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "```\n",
        "### **2. Define the Neural Network Class**\n",
        "\n",
        "* Inherit from `nn.Module`.\n",
        "* Define layers inside `__init__`.\n",
        "* Define how data flows through layers in `forward`.\n",
        "\n",
        "```python\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "\n",
        "        # Define layers\n",
        "        self.fc1 = nn.Linear(784, 128)   # Input → Hidden (e.g., 784 for MNIST)\n",
        "        self.fc2 = nn.Linear(128, 64)    # Hidden → Hidden\n",
        "        self.fc3 = nn.Linear(64, 10)     # Hidden → Output (10 classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass (data flow)\n",
        "        x = F.relu(self.fc1(x))   # Activation function\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)           # Output layer (logits)\n",
        "        return x\n",
        "```\n",
        "### **3. Create a Model Instance**\n",
        "\n",
        "```python\n",
        "model = SimpleNN()\n",
        "print(model)\n",
        "```\n",
        "### **4. Add Optimizer and Loss Function**\n",
        "\n",
        "```python\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()   # Loss function\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)   # Optimizer\n",
        "```\n",
        "### **5. Training Loop (basic structure)**\n",
        "\n",
        "```python\n",
        "for epoch in range(10):\n",
        "    for data, target in dataloader:\n",
        "        optimizer.zero_grad()      # Reset gradients\n",
        "        output = model(data)       # Forward pass\n",
        "        loss = criterion(output, target)  # Compute loss\n",
        "        loss.backward()            # Backpropagation\n",
        "        optimizer.step()           # Update weights\n",
        "```\n",
        "✅ **Summary:**\n",
        "A PyTorch neural network has this **basic structure**:\n",
        "\n",
        "1. **Define the model** using `nn.Module` (`__init__` for layers, `forward()` for flow).\n",
        "2. **Choose a loss function** (`nn.CrossEntropyLoss`, `nn.MSELoss`, etc.).\n",
        "3. **Choose an optimizer** (`SGD`, `Adam`, etc.).\n",
        "4. **Training loop**: forward pass → loss → backward pass → update."
      ],
      "metadata": {
        "id": "nWL-Z91fKddj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#13 What is the significance of tensors in PyTorch ?\n",
        "Great question! 🚀\n",
        "\n",
        "In **PyTorch**, **tensors** are the **core data structure**, just like **NumPy arrays**, but with additional superpowers designed for **deep learning and GPU acceleration**.\n",
        "## 🔑 **Significance of Tensors in PyTorch**\n",
        "\n",
        "### 1. **Primary Data Structure**\n",
        "\n",
        "* Everything in PyTorch (inputs, outputs, weights, gradients) is represented as a **tensor**.\n",
        "* Example:\n",
        "\n",
        "  ```python\n",
        "  import torch\n",
        "  x = torch.tensor([[1, 2], [3, 4]])\n",
        "  print(x)\n",
        "  ```\n",
        "### 2. **Similar to NumPy Arrays, but More Powerful**\n",
        "\n",
        "* Tensors support operations like addition, multiplication, reshaping, slicing (like `numpy`).\n",
        "* BUT they can also run seamlessly on **GPU** for speed.\n",
        "* Example:\n",
        "\n",
        "  ```python\n",
        "  x = torch.tensor([1.0, 2.0, 3.0])\n",
        "  x_gpu = x.to('cuda')   # Move tensor to GPU\n",
        "  ```\n",
        "### 3. **Automatic Differentiation (Autograd)**\n",
        "\n",
        "* Tensors can track operations performed on them when `requires_grad=True`.\n",
        "* This enables **backpropagation** in neural networks automatically.\n",
        "* Example:\n",
        "\n",
        "  ```python\n",
        "  x = torch.tensor(2.0, requires_grad=True)\n",
        "  y = x**2\n",
        "  y.backward()\n",
        "  print(x.grad)   # dy/dx = 2x = 4\n",
        "  ```\n",
        "### 4. **Bridge Between Data and Models**\n",
        "\n",
        "* Training data → **Tensor**\n",
        "* Model parameters (weights & biases) → **Tensor**\n",
        "* Gradients → **Tensor**\n",
        "* Thus, **all computations in PyTorch are tensor operations**.\n",
        "### 5. **Highly Optimized Performance**\n",
        "\n",
        "* PyTorch uses optimized backends (**C/CUDA, cuDNN, MKL**) for tensor operations.\n",
        "* This makes deep learning training very efficient.\n",
        "✅ **In summary:**\n",
        "Tensors in PyTorch are the **fundamental building blocks** for representing data and parameters. They combine the flexibility of NumPy arrays with the power of GPUs and automatic differentiation—making them essential for building and training deep learning models."
      ],
      "metadata": {
        "id": "z6dUoaPPLHBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 14 What is the difference between torch.Tensor and torch.cuda.Tensor in PyTorch2 ?\n",
        "Good question 👍 This confuses many beginners in PyTorch.\n",
        "\n",
        "Let’s break it down:\n",
        "## 🔑 **1. `torch.Tensor`**\n",
        "\n",
        "* The **default tensor type** in PyTorch.\n",
        "* Usually created on the **CPU** (unless you explicitly move it to GPU).\n",
        "* Example:\n",
        "\n",
        "  ```python\n",
        "  import torch\n",
        "  a = torch.Tensor([1, 2, 3])   # By default on CPU\n",
        "  print(a.device)   # cpu\n",
        "  ```\n",
        "## 🔑 **2. `torch.cuda.Tensor`**\n",
        "\n",
        "* A tensor stored on a **GPU device**.\n",
        "* Allows **fast parallel computation** using CUDA (NVIDIA GPU backend).\n",
        "* You don’t create `torch.cuda.Tensor` directly most of the time—instead, you move a normal tensor to GPU:\n",
        "\n",
        "  ```python\n",
        "  b = torch.Tensor([1, 2, 3]).to('cuda')  # Move to GPU\n",
        "  print(b.device)  # cuda:0\n",
        "  ```\n",
        "## ⚖️ **Key Differences**\n",
        "\n",
        "| Feature               | `torch.Tensor` (CPU)                               | `torch.cuda.Tensor` (GPU)               |\n",
        "| --------------------- | -------------------------------------------------- | --------------------------------------- |\n",
        "| **Device**            | Stored in CPU memory                               | Stored in GPU (CUDA) memory             |\n",
        "| **Computation speed** | Slower for large data (serial/limited parallelism) | Much faster for deep learning workloads |\n",
        "| **Usage**             | Default, general-purpose                           | Used when training models on GPU        |\n",
        "| **Conversion**        | Default tensor type                                | Created by `.to('cuda')` or `.cuda()`   |\n",
        "| **Example**           | `torch.tensor([1,2])`                              | `torch.tensor([1,2]).cuda()`            |\n",
        "\n",
        "## ✅ Example: Comparing CPU vs GPU\n",
        "\n",
        "```python\n",
        "x_cpu = torch.randn(1000, 1000)        # CPU tensor\n",
        "x_gpu = torch.randn(1000, 1000, device='cuda')  # GPU tensor\n",
        "\n",
        "# Matrix multiplication (will be much faster on GPU)\n",
        "y_cpu = torch.mm(x_cpu, x_cpu)\n",
        "y_gpu = torch.mm(x_gpu, x_gpu)\n",
        "```\n",
        "## ⚠️ Important Notes\n",
        "\n",
        "* You **cannot** directly operate between a CPU tensor and a GPU tensor. They must be on the same device:\n",
        "\n",
        "  ```python\n",
        "  a = torch.tensor([1,2])\n",
        "  b = torch.tensor([3,4], device='cuda')\n",
        "  a + b   # ❌ RuntimeError\n",
        "  ``\n",
        "  Fix:\n",
        "\n",
        "  ```python\n",
        "  a = a.to('cuda')\n",
        "  c = a + b  # ✅ Now both on GPU\n",
        "  ```\n",
        "✅ **In short:**\n",
        "\n",
        "* `torch.Tensor` → Default CPU tensor.\n",
        "* `torch.cuda.Tensor` → Tensor stored on GPU for accelerated computation.\n",
        "* Use `.to('cuda')` or `.cuda()` to move between them"
      ],
      "metadata": {
        "id": "kx795p8HUxop"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}